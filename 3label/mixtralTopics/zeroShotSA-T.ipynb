{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c9951f-de7d-422b-823e-751ce2257bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ddda98-7f34-41d2-b798-6f46879c2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "apiKey = \"fill_it_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77994b44-478a-4729-8611-3b77a25ee5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    # api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    api_key= apiKey,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4c777-0b4d-45c5-b3c6-bbf91516f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"test3label/keyphrases/done/keyphrases_AmazonMixtral_Done.csv\")\n",
    "# dataset = pd.read_csv(\"test3label/keyphrases/done/keyphrases_NetflixMixtral_Done.csv\")\n",
    "# dataset = pd.read_csv(\"test3label/keyphrases/done/keyphrases_SpotifyMixtral_Done.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4028ed-14ea-4b0d-a715-d6b5876b5e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fd768-775b-4a8b-b5a6-84689845ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_counts_balanced = dataset['sentiment'].value_counts().sort_index()\n",
    "print(score_counts_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1962b3-0b01-4d1c-bde1-511050e8b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset[['content', 'sentiment', 'Merged keyphrases_reduced 2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2c8a6-58a8-474a-ae0d-2063b78becc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830178eb-0a18-4663-a59d-1788f6631607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list = []\n",
    "for index, row in train_data.iterrows():\n",
    "    text = row['content']\n",
    "    topics = row['Merged keyphrases_reduced 2']\n",
    "    \n",
    "    string_message = f\"\"\"Considering the provided text and the set of topics/keyphrases I need you to analyze the sentiment and classify it into one of the five categories: 1 - negative, 2 - neutral, or 3 - positive.\n",
    "                Text: \"{text}\"\n",
    "                Topics/Keyphrases: \"{topics}\"\n",
    "                Please just provide the sentiment classification as a single number (1, 2, or 3) and nothing more.\n",
    "                \"\"\"\n",
    "    print(\"\\n\\n\")\n",
    "    print(string_message)\n",
    "    print(\"\\n\")\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"{string_message}\"\"\"\n",
    "            }\n",
    "    \n",
    "        ],\n",
    "        # model=\"llama3-8b-8192\",\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "    )\n",
    "    armaz = chat_completion.choices[0].message.content\n",
    "    print(f'{index}:\\t{armaz}')\n",
    "    list.append(armaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7848ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba00f41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rest = train_data[len(list):]\n",
    "for index, row in rest.iterrows():\n",
    "    text = row['content']\n",
    "    topics = row['Merged keyphrases_reduced 2']\n",
    "    \n",
    "    string_message = f\"\"\"Considering the provided text and the set of topics/keyphrases I need you to analyze the sentiment and classify it into one of the five categories: 1 - negative, 2 - neutral, or 3 - positive.\n",
    "                Text: \"{text}\"\n",
    "                Topics/Keyphrases: \"{topics}\"\n",
    "                Please just provide the sentiment classification as a single number (1, 2, or 3) and nothing more.\n",
    "                \"\"\"\n",
    "    print(\"\\n\\n\")\n",
    "    print(string_message)\n",
    "    print(\"\\n\")\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"{string_message}\"\"\"\n",
    "            }\n",
    "    \n",
    "        ],\n",
    "        # model=\"llama3-8b-8192\",\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "    )\n",
    "    armaz = chat_completion.choices[0].message.content\n",
    "    print(f'{index}:\\t{armaz}')\n",
    "    list.append(armaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39d430-c1c0-4db5-824b-c5b6b973ce85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4790e-b5c2-4c78-980d-b529ccff0536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['predictedSentiment'] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6f5b2-37a9-467f-9547-0078a9fa2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def findNumbers(string):\n",
    "    # Find all numbers in the string\n",
    "    numbers = re.findall(r'\\d+', string)\n",
    "    \n",
    "    # Convert the numbers to integers\n",
    "    numbers = [int(x) for x in numbers]\n",
    "    x = None\n",
    "    if(len(numbers)>0):\n",
    "        x = numbers[0]-1\n",
    "    else:\n",
    "        x = -1\n",
    "    if ((x < 0) or (x > 5)):\n",
    "        x = -1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345af7a-5900-4033-8a93-760c4fe213f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "formated = train_data['predictedSentiment'].apply(findNumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345ca9b-fabb-4b80-96e0-b80c35eadd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['predictedSentiment'] = formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49172a7-64e8-4f77-b8a4-8a9162125078",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c52c78-2cd1-4f8e-8e45-e15312e86971",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('mixtralOutput/topics/filenameAmazonZeroShotMixtral-T.csv', index=False)\n",
    "# train_data.to_csv('mixtralOutput/topics/filenameNetflixZeroShotMixtral-T.csv', index=False)\n",
    "# train_data.to_csv('mixtralOutput/topics/filenameSpotifyZeroShotMixtral-T.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129beb56-7a49-4006-9413-b3602e063214",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"mixtralOutput/topics/filenameAmazonZeroShotMixtral-T.csv\")\n",
    "# results = pd.read_csv(\"mixtralOutput/topics/filenameNetflixZeroShotMixtral-T.csv\")\n",
    "# results = pd.read_csv(\"mixtralOutput/topics/filenameSpotifyZeroShotMixtral-T.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9302f2-6c19-4b27-97f2-4b0ae0966dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76eb963-bfd0-4c7c-b1d0-bfe024f9fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['predictedSentiment'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cb9d1-dd9c-4854-8419-9648282d2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = results[results[\"predictedSentiment\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342cb98-0b35-4adc-b641-68c000caf960",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb610be-3340-4575-bf27-5b5a91f19176",
   "metadata": {},
   "outputs": [],
   "source": [
    "newResults = results[results[\"predictedSentiment\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e985f-2774-4bf1-91a1-de86e1c1d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7c927-9f0d-4c55-92fb-7cb6e1812911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cm_analysis(y_true, y_pred, filename, labels, classes, ymap=None, figsize=(17,17)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      classes:   aliases for the labels. String array to be shown in the cm plot.\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    sns.set(font_scale=2.8)\n",
    "\n",
    "    if ymap is not None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.2f%%\\n%d/%d' % (p, c, s)\n",
    "            #elif c == 0:\n",
    "            #    annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.2f%%\\n%d' % (p, c)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels, normalize='true')\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm = cm * 100\n",
    "    cm.index.name = 'True Label'\n",
    "    cm.columns.name = 'Predicted Label'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.yticks(va='center')\n",
    "\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, xticklabels=classes, cbar=True, cbar_kws={'format':PercentFormatter()}, yticklabels=classes, cmap=\"Blues\")\n",
    "    plt.savefig(f'{filename}.png',  bbox_inches='tight')\n",
    "    plt.savefig(f'{filename}.svg',  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271c7ce-3c4b-4548-ac8d-1fd03dcbef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "unique_labels = np.sort(newResults['scoreSA'].unique())\n",
    "mapping = {0: 'Very Negative (1)', 1: 'Negative (2)', 2: 'Neutral (3)', 3: 'Positive (4)', 4: 'Very Positive (5)'}\n",
    "\n",
    "# Applying mapping\n",
    "classes = [mapping[value] for value in unique_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277fc98a-f8a1-47d6-8635-81fb246dd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_analysis(newResults['scoreSA'], newResults['predictedSentiment'], 'API', unique_labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b64a6-3866-4630-a698-b5acdaba7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support, mean_absolute_error\n",
    "\n",
    "accuracy = accuracy_score(newResults['scoreSA'], newResults['predictedSentiment'])\n",
    "precision_ALL = precision_score(newResults['scoreSA'], newResults['predictedSentiment'], average='macro')\n",
    "recall_ALL = recall_score(newResults['scoreSA'], newResults['predictedSentiment'], average='macro')\n",
    "f1_ALL = f1_score(newResults['scoreSA'], newResults['predictedSentiment'], average='macro')\n",
    "mae_ALL = mean_absolute_error(newResults['scoreSA'], newResults['predictedSentiment'])\n",
    "precision, recall, f1, support = precision_recall_fscore_support(newResults['scoreSA'], newResults['predictedSentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69e1b1-6bd7-4c44-a9a1-79a151e749d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for each class\n",
    "for i in range(len(unique_labels)):\n",
    "    temp = newResults[newResults[\"scoreSA\"] == i]\n",
    "    value = accuracy_score(temp['scoreSA'], temp['predictedSentiment'])\n",
    "    print(f'Label:\\t{i}\\t-\\tValue:\\t{value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56bc89-7b8e-4e9b-9d4e-c7b6fbc9eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304855d2-f840-4642-9b47-cceabc664ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy = balanced_accuracy_score(results['scoreSA'], results['predictedSentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5359fc4-672e-494d-9c29-1b7b5bc6742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e2b25-67fa-46be-adfc-85e2ee0b93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d006bf2-44ae-4ebe-842d-9b1491ba81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c577e-f685-45be-91d7-aefc5c2d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1468b-1d72-4c77-a6b2-0490cac68a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7270e0-e59b-4c5f-b564-5d43ab6f947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b47d4-f2a7-4ccd-8cbe-a9f694d238c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840f501-1dc9-44b8-8a9c-58635581916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c968bd-c651-4dae-99f5-4054572fca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "support"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
